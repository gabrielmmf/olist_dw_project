This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2025-06-22T23:12:22.057Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
metadata/
  rdbms/
    olist_db.json
pipelines/
  transform_orders.hpl
project-config.json
README.md

================================================================
Repository Files
================================================================

================
File: metadata/rdbms/olist_db.json
================
{
  "virtualPath": "/TP_DW",
  "rdbms": {
    "SQLITE": {
      "databaseName": "",
      "pluginId": "SQLITE",
      "accessType": 0,
      "hostname": "",
      "password": "Encrypted ",
      "pluginName": "SQLite",
      "port": "",
      "attributes": {
        "SUPPORTS_TIMESTAMP_DATA_TYPE": "N",
        "QUOTE_ALL_FIELDS": "N",
        "SUPPORTS_BOOLEAN_DATA_TYPE": "N",
        "FORCE_IDENTIFIERS_TO_LOWERCASE": "N",
        "PRESERVE_RESERVED_WORD_CASE": "Y",
        "SQL_CONNECT": "",
        "FORCE_IDENTIFIERS_TO_UPPERCASE": "N",
        "PREFERRED_SCHEMA_NAME": ""
      },
      "manualUrl": "jdbc:sqlite:/home/gabrielmmf/TP_DW/brazilian-ecommerce.sqlite",
      "username": ""
    }
  },
  "name": "olist_db"
}

================
File: pipelines/transform_orders.hpl
================
<?xml version="1.0" encoding="UTF-8"?>
<pipeline>
  <info>
    <name>transform_orders</name>
    <name_sync_with_filename>Y</name_sync_with_filename>
    <description/>
    <extended_description/>
    <pipeline_version/>
    <pipeline_type>Normal</pipeline_type>
    <parameters>
    </parameters>
    <capture_transform_performance>N</capture_transform_performance>
    <transform_performance_capturing_delay>1000</transform_performance_capturing_delay>
    <transform_performance_capturing_size_limit>100</transform_performance_capturing_size_limit>
    <created_user>-</created_user>
    <created_date>2025/06/15 18:19:16.911</created_date>
    <modified_user>-</modified_user>
    <modified_date>2025/06/15 18:19:16.911</modified_date>
  </info>
  <notepads>
  </notepads>
  <order>
    <hop>
      <from>Select values</from>
      <to>Calculator</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Calculator</from>
      <to>Text file output</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>CSV file input</from>
      <to>Filter rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Filter rows</from>
      <to>Select values</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <transform>
    <name>CSV file input</name>
    <type>CSVInput</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <filename>${PROJECT_HOME}/original_dataset/olist_orders_dataset.csv</filename>
    <filename_field/>
    <rownum_field/>
    <include_filename>N</include_filename>
    <separator>,</separator>
    <enclosure>"</enclosure>
    <header>Y</header>
    <buffer_size>50000</buffer_size>
    <schemaDefinition/>
    <lazy_conversion>Y</lazy_conversion>
    <add_filename_result>N</add_filename_result>
    <parallel>N</parallel>
    <newline_possible>N</newline_possible>
    <encoding/>
    <fields>
      <field>
        <name>order_id</name>
        <type>String</type>
        <format/>
        <currency>$</currency>
        <decimal>.</decimal>
        <group>,</group>
        <length>32</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>customer_id</name>
        <type>String</type>
        <format/>
        <currency>$</currency>
        <decimal>.</decimal>
        <group>,</group>
        <length>32</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>order_status</name>
        <type>String</type>
        <format/>
        <currency>$</currency>
        <decimal>.</decimal>
        <group>,</group>
        <length>9</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>order_purchase_timestamp</name>
        <type>Date</type>
        <format>yyyy-MM-dd HH:mm:ss</format>
        <currency>$</currency>
        <decimal>.</decimal>
        <group>,</group>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>order_approved_at</name>
        <type>Date</type>
        <format>yyyy-MM-dd HH:mm:ss</format>
        <currency>$</currency>
        <decimal>.</decimal>
        <group>,</group>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>order_delivered_carrier_date</name>
        <type>Date</type>
        <format>yyyy-MM-dd HH:mm:ss</format>
        <currency>$</currency>
        <decimal>.</decimal>
        <group>,</group>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>order_delivered_customer_date</name>
        <type>Date</type>
        <format>yyyy-MM-dd HH:mm:ss</format>
        <currency>$</currency>
        <decimal>.</decimal>
        <group>,</group>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>order_estimated_delivery_date</name>
        <type>Date</type>
        <format>yyyy-MM-dd HH:mm:ss</format>
        <currency>$</currency>
        <decimal>.</decimal>
        <group>,</group>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
    </fields>
    <attributes/>
    <GUI>
      <xloc>80</xloc>
      <yloc>144</yloc>
    </GUI>
  </transform>
  <transform>
    <name>Calculator</name>
    <type>Calculator</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <calculation>
      <calc_type>DATE_DIFF</calc_type>
      <field_a>order_delivered_customer_date</field_a>
      <field_b>order_purchase_timestamp</field_b>
      <field_name>dias_entrega</field_name>
      <remove>N</remove>
      <value_length>-1</value_length>
      <value_precision>-1</value_precision>
    </calculation>
    <failIfNoFile>Y</failIfNoFile>
    <attributes/>
    <GUI>
      <xloc>576</xloc>
      <yloc>144</yloc>
    </GUI>
  </transform>
  <transform>
    <name>Filter rows</name>
    <type>FilterRows</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <compare>
      <condition>
        <conditions>
          <condition>
            <conditions>
</conditions>
            <function>IS NULL</function>
            <leftvalue>order_purchase_timestamp</leftvalue>
            <negated>N</negated>
            <operator>AND</operator>
          </condition>
          <condition>
            <conditions>
</conditions>
            <function>IS NULL</function>
            <leftvalue>order_delivered_customer_date</leftvalue>
            <negated>N</negated>
            <operator>OR</operator>
          </condition>
        </conditions>
        <function>=</function>
        <negated>N</negated>
        <operator>-</operator>
      </condition>
    </compare>
    <send_false_to>Select values</send_false_to>
    <attributes/>
    <GUI>
      <xloc>240</xloc>
      <yloc>144</yloc>
    </GUI>
  </transform>
  <transform>
    <name>Select values</name>
    <type>SelectValues</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
      <field>
        <length>-2</length>
        <name>order_id</name>
        <precision>-2</precision>
      </field>
      <field>
        <length>-2</length>
        <name>customer_id</name>
        <precision>-2</precision>
      </field>
      <field>
        <length>-2</length>
        <name>order_purchase_timestamp</name>
        <precision>-2</precision>
      </field>
      <field>
        <length>-2</length>
        <name>order_delivered_customer_date</name>
        <precision>-2</precision>
      </field>
      <select_unspecified>N</select_unspecified>
    </fields>
    <attributes/>
    <GUI>
      <xloc>368</xloc>
      <yloc>144</yloc>
    </GUI>
  </transform>
  <transform>
    <name>Text file output</name>
    <type>TextFileOutput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <schema_definition/>
    <separator>;</separator>
    <enclosure>"</enclosure>
    <enclosure_forced>N</enclosure_forced>
    <enclosure_fix_disabled>N</enclosure_fix_disabled>
    <header>Y</header>
    <footer>N</footer>
    <format>DOS</format>
    <compression>None</compression>
    <encoding>UTF-8</encoding>
    <endedLine/>
    <fileNameInField>N</fileNameInField>
    <fileNameField/>
    <create_parent_folder>Y</create_parent_folder>
    <file>
      <name>${PROJECT_HOME}/output/transformed_orders.csv</name>
      <servlet_output>N</servlet_output>
      <do_not_open_new_file_init>Y</do_not_open_new_file_init>
      <extention/>
      <append>N</append>
      <split>N</split>
      <haspartno>N</haspartno>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <SpecifyFormat>N</SpecifyFormat>
      <date_time_format/>
      <add_to_result_filenames>Y</add_to_result_filenames>
      <pad>N</pad>
      <fast_dump>N</fast_dump>
      <splitevery/>
    </file>
    <fields>
    </fields>
    <attributes/>
    <GUI>
      <xloc>752</xloc>
      <yloc>144</yloc>
    </GUI>
  </transform>
  <transform_error_handling>
  </transform_error_handling>
  <attributes/>
</pipeline>

================
File: project-config.json
================
{
  "metadataBaseFolder" : "${PROJECT_HOME}/metadata",
  "unitTestsBasePath" : "${PROJECT_HOME}",
  "dataSetsCsvFolder" : "${PROJECT_HOME}/datasets",
  "enforcingExecutionInHome" : true,
  "parentProjectName" : "default",
  "config" : {
    "variables" : [ ]
  }
}

================
File: README.md
================
* Como rodar e contribuir com os **pipelines do Apache Hop**
* Explica√ß√£o da **estrutura de diret√≥rios**
* Vis√£o geral da **arquitetura**
* Guia de contribui√ß√£o

---

````markdown
# üì¶ Projeto Data Warehouse Olist

Este reposit√≥rio cont√©m um projeto completo de Data Warehouse baseado no dataset **[Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)**. Ele usa o **Apache Hop** como ferramenta principal de ETL, com armazenamento anal√≠tico em **ClickHouse** e visualiza√ß√µes em **Superset**.

---

## üìÅ Estrutura do Projeto

```plaintext
olist_dw_project/
‚îú‚îÄ‚îÄ README.md                        # Instru√ß√µes e documenta√ß√£o
‚îú‚îÄ‚îÄ raw_csvs/                        # Arquivos originais extra√≠dos do .sqlite ou Kaggle
‚îÇ   ‚îî‚îÄ‚îÄ olist_orders_dataset.csv
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ hop_project/                     # Projeto Apache Hop
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/                   # Transforma√ß√µes unit√°rias (.hpl)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transform_orders.hpl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transform_customers.hpl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ workflows/                   # Workflows para orquestra√ß√£o (.hwf)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main_etl_workflow.hwf
‚îÇ   ‚îú‚îÄ‚îÄ metadata/                    # Conex√µes, vari√°veis e ambiente
‚îÇ   ‚îî‚îÄ‚îÄ hop-config.json              # Configura√ß√£o do projeto
‚îú‚îÄ‚îÄ transformed/                     # Dados limpos e prontos para carga no DW
‚îÇ   ‚îî‚îÄ‚îÄ dim_cliente.csv
‚îÇ   ‚îî‚îÄ‚îÄ fato_vendas.csv
‚îú‚îÄ‚îÄ dw_clickhouse/                   # Scripts SQL de cria√ß√£o das tabelas no DW
‚îÇ   ‚îî‚îÄ‚îÄ create_dim_cliente.sql
‚îÇ   ‚îî‚îÄ‚îÄ create_fato_vendas.sql
‚îú‚îÄ‚îÄ dw_model_pgmodeler/             # Modelo dimensional (.dbm, imagens, etc)
‚îú‚îÄ‚îÄ dashboards_superset/            # Dashboards criados no Superset
‚îî‚îÄ‚îÄ docs/                            # Relat√≥rio, slides e materiais de apresenta√ß√£o
````

---

## ‚öôÔ∏è Tecnologias utilizadas

| Etapa                 | Ferramenta         |
| --------------------- | ------------------ |
| ETL                   | Apache Hop         |
| Modelagem Dimensional | pgModeler          |
| Armazenamento DW      | ClickHouse         |
| Visualiza√ß√£o          | Apache Superset    |
| Dataset               | Olist (via Kaggle) |

---

## üèóÔ∏è Arquitetura

```plaintext
.raw_csvs/ ‚ûú Apache Hop ‚ûú .transformed/ ‚ûú ClickHouse ‚ûú Superset
```

* **Extra√ß√£o**: CSVs extra√≠dos do SQLite original do Kaggle
* **Transforma√ß√£o (Hop)**:

  * Pipelines independentes por entidade (clientes, pedidos, produtos...)
  * Um workflow principal (`main_etl_workflow.hwf`) orquestra tudo
* **Carga**: os CSVs transformados s√£o importados no ClickHouse como tabelas anal√≠ticas
* **Visualiza√ß√£o**: os dashboards s√£o feitos com Apache Superset diretamente conectado ao DW

---

## üöÄ Executando o Projeto

### 1. Clonar o reposit√≥rio

```bash
git clone https://github.com/seuusuario/olist-dw-project.git
cd olist-dw-project
```

### 2. Instalar o Apache Hop

* Baixe em: [https://hop.apache.org/download](https://hop.apache.org/download)
* Extraia e execute o `hop-gui`

### 3. Configurar o projeto no Hop

1. V√° em **Project ‚Üí Create Project**
2. Nome: `olist_dw_project`
3. Diret√≥rio: `./hop_project/`

> Voc√™ tamb√©m pode importar os `.hpl` e `.hwf` manualmente.

### 4. Rodar os pipelines

* Abra o `Workflow` em `hop_project/workflows/main_etl_workflow.hwf`
* Clique em "Run" para executar a orquestra√ß√£o completa

---

## üìä Tabelas do DW

### üßæ Fato

| Nome         | Descri√ß√£o                                          |
| ------------ | -------------------------------------------------- |
| fato\_vendas | Cada linha representa um item vendido (order item) |

### üß± Dimens√µes

* `dim_cliente`
* `dim_produto`
* `dim_data`
* `dim_vendedor`
* `dim_pagamento`
* `dim_avaliacao`

---

## ü§ù Como Contribuir

### 1. Requisitos

* Java 11 ou superior
* Apache Hop
* (opcional) pgModeler ou DB-Main
* ClickHouse (ou MySQL/PostgreSQL)

### 2. Recomenda√ß√µes

* Cada nova pipeline deve estar dentro de `hop_project/pipelines/`
* Nomeie com `transform_<nome>.hpl`
* Sempre valide com `Preview` antes de rodar o workflow principal

### 3. Para adicionar um novo pipeline:

1. Crie a pipeline no Hop GUI
2. Salve em `pipelines/`
3. Atualize o `main_etl_workflow.hwf` para inclu√≠-la
4. Teste localmente

### 4. Sugest√µes de melhorias

* Adi√ß√£o de novas dimens√µes (ex: comportamento de review)
* Gera√ß√£o automatizada de relat√≥rios com Hop ou Superset API
* Substituir arquivos CSV por tabelas intermedi√°rias em banco

---

## üìò Refer√™ncias

* [Apache Hop Docs](https://hop.apache.org/docs/)
* [ClickHouse Docs](https://clickhouse.com/docs/)
* [Superset Docs](https://superset.apache.org/)
* [Olist Dataset Kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
